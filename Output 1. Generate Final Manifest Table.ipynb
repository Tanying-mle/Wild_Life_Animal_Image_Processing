{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac532141-a1db-4577-8da1-d46b7ffdb66b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /databricks/python3/lib/python3.12/site-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.12/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /databricks/python3/lib/python3.12/site-packages (from torch) (4.11.0)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.12/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.12/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.12/site-packages (from torch) (2023.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /databricks/python3/lib/python3.12/site-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /databricks/python3/lib/python3.12/site-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /databricks/python3/lib/python3.12/site-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /databricks/python3/lib/python3.12/site-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /databricks/python3/lib/python3.12/site-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /databricks/python3/lib/python3.12/site-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /databricks/python3/lib/python3.12/site-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /databricks/python3/lib/python3.12/site-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /databricks/python3/lib/python3.12/site-packages (from torch) (3.2.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (74.0.0)\nRequirement already satisfied: sympy==1.13.1 in /databricks/python3/lib/python3.12/site-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: ultralytics in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (8.3.235)\nRequirement already satisfied: numpy>=1.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from ultralytics) (2.2.6)\nRequirement already satisfied: matplotlib>=3.3.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics) (3.8.4)\nRequirement already satisfied: opencv-python>=4.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from ultralytics) (12.0.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /databricks/python3/lib/python3.12/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics) (2.32.2)\nRequirement already satisfied: scipy>=1.4.1 in /databricks/python3/lib/python3.12/site-packages (from ultralytics) (1.13.1)\nRequirement already satisfied: torch>=1.8.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: psutil>=5.8.0 in /databricks/python3/lib/python3.12/site-packages (from ultralytics) (5.9.0)\nRequirement already satisfied: polars>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from ultralytics) (1.36.1)\nRequirement already satisfied: ultralytics-thop>=2.0.18 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from ultralytics) (2.0.18)\nRequirement already satisfied: contourpy>=1.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: polars-runtime-32==1.36.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from polars>=0.20.0->ultralytics) (1.36.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\nRequirement already satisfied: fsspec in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2023.5.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (74.0.0)\nRequirement already satisfied: sympy==1.13.1 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.12/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: pytesseract in /databricks/python3/lib/python3.12/site-packages (0.3.10)\nRequirement already satisfied: packaging>=21.3 in /databricks/python3/lib/python3.12/site-packages (from pytesseract) (24.1)\nRequirement already satisfied: Pillow>=8.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from pytesseract) (12.0.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: config in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (0.5.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: yolov5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (7.0.14)\nRequirement already satisfied: gitpython>=3.1.30 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (3.1.37)\nRequirement already satisfied: matplotlib>=3.3 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (3.8.4)\nRequirement already satisfied: numpy>=1.18.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from yolov5) (2.2.6)\nRequirement already satisfied: opencv-python>=4.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from yolov5) (4.11.0.86)\nRequirement already satisfied: Pillow>=7.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from yolov5) (12.0.0)\nRequirement already satisfied: psutil in /databricks/python3/lib/python3.12/site-packages (from yolov5) (5.9.0)\nRequirement already satisfied: PyYAML>=5.3.1 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (2.32.2)\nRequirement already satisfied: scipy>=1.4.1 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (1.13.1)\nRequirement already satisfied: thop>=0.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from yolov5) (0.1.1.post2209072238)\nRequirement already satisfied: torch>=1.7.0 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.8.1 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.64.0 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (4.66.4)\nRequirement already satisfied: ultralytics>=8.0.100 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from yolov5) (8.3.235)\nRequirement already satisfied: tensorboard>=2.4.1 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (2.17.0)\nRequirement already satisfied: pandas>=1.1.4 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (1.5.3)\nRequirement already satisfied: seaborn>=0.11.0 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (0.13.2)\nRequirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.12/dist-packages (from yolov5) (74.0.0)\nRequirement already satisfied: fire in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from yolov5) (0.7.1)\nRequirement already satisfied: boto3>=1.19.1 in /databricks/python3/lib/python3.12/site-packages (from yolov5) (1.34.69)\nRequirement already satisfied: sahi>=0.11.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from yolov5) (0.11.36)\nRequirement already satisfied: huggingface-hub<0.25.0,>=0.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from yolov5) (0.24.7)\nRequirement already satisfied: roboflow>=0.2.29 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from yolov5) (1.2.11)\nRequirement already satisfied: botocore<1.35.0,>=1.34.69 in /databricks/python3/lib/python3.12/site-packages (from boto3>=1.19.1->yolov5) (1.34.69)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /databricks/python3/lib/python3.12/site-packages (from boto3>=1.19.1->yolov5) (1.0.1)\nRequirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /databricks/python3/lib/python3.12/site-packages (from boto3>=1.19.1->yolov5) (0.10.2)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitpython>=3.1.30->yolov5) (4.0.11)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.12/site-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.12/site-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (2023.5.0)\nRequirement already satisfied: packaging>=20.9 in /databricks/python3/lib/python3.12/site-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (24.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /databricks/python3/lib/python3.12/site-packages (from huggingface-hub<0.25.0,>=0.12.0->yolov5) (4.11.0)\nRequirement already satisfied: contourpy>=1.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from matplotlib>=3.3->yolov5) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3->yolov5) (0.11.0)\nRequirement already satisfied: fonttools>=4.22.0 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3->yolov5) (4.51.0)\nRequirement already satisfied: kiwisolver>=1.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3->yolov5) (1.4.4)\nRequirement already satisfied: pyparsing>=2.3.1 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3->yolov5) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.12/site-packages (from matplotlib>=3.3->yolov5) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.12/site-packages (from pandas>=1.1.4->yolov5) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->yolov5) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->yolov5) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->yolov5) (1.26.16)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.23.0->yolov5) (2024.6.2)\nRequirement already satisfied: opencv-python-headless==4.10.0.84 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from roboflow>=0.2.29->yolov5) (4.10.0.84)\nRequirement already satisfied: pi-heif<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from roboflow>=0.2.29->yolov5) (1.1.1)\nRequirement already satisfied: pillow-avif-plugin<2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from roboflow>=0.2.29->yolov5) (1.5.2)\nRequirement already satisfied: python-dotenv in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from roboflow>=0.2.29->yolov5) (1.2.1)\nRequirement already satisfied: six in /usr/lib/python3/dist-packages (from roboflow>=0.2.29->yolov5) (1.16.0)\nRequirement already satisfied: requests-toolbelt in /databricks/python3/lib/python3.12/site-packages (from roboflow>=0.2.29->yolov5) (1.0.0)\nRequirement already satisfied: filetype in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from roboflow>=0.2.29->yolov5) (1.2.0)\nRequirement already satisfied: click in /databricks/python3/lib/python3.12/site-packages (from sahi>=0.11.10->yolov5) (8.1.7)\nRequirement already satisfied: pybboxes==0.1.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from sahi>=0.11.10->yolov5) (0.1.6)\nRequirement already satisfied: shapely>=2.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from sahi>=0.11.10->yolov5) (2.1.2)\nRequirement already satisfied: terminaltables in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from sahi>=0.11.10->yolov5) (3.1.10)\nRequirement already satisfied: absl-py>=0.4 in /databricks/python3/lib/python3.12/site-packages (from tensorboard>=2.4.1->yolov5) (1.0.0)\nRequirement already satisfied: grpcio>=1.48.2 in /databricks/python3/lib/python3.12/site-packages (from tensorboard>=2.4.1->yolov5) (1.60.0)\nRequirement already satisfied: markdown>=2.6.8 in /databricks/python3/lib/python3.12/site-packages (from tensorboard>=2.4.1->yolov5) (3.4.1)\nRequirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /databricks/python3/lib/python3.12/site-packages (from tensorboard>=2.4.1->yolov5) (4.24.1)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /databricks/python3/lib/python3.12/site-packages (from tensorboard>=2.4.1->yolov5) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /databricks/python3/lib/python3.12/site-packages (from tensorboard>=2.4.1->yolov5) (3.0.3)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (3.2.1)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /databricks/python3/lib/python3.12/site-packages (from torch>=1.7.0->yolov5) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /databricks/python3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.7.0->yolov5) (1.3.0)\nRequirement already satisfied: polars>=0.20.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from ultralytics>=8.0.100->yolov5) (1.36.1)\nRequirement already satisfied: ultralytics-thop>=2.0.18 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from ultralytics>=8.0.100->yolov5) (2.0.18)\nRequirement already satisfied: termcolor in /databricks/python3/lib/python3.12/site-packages (from fire->yolov5) (3.0.1)\nRequirement already satisfied: smmap<6,>=3.0.1 in /databricks/python3/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->yolov5) (5.0.0)\nRequirement already satisfied: polars-runtime-32==1.36.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from polars>=0.20.0->ultralytics>=8.0.100->yolov5) (1.36.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /databricks/python3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->yolov5) (2.1.3)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting faiss-cpu\n  Using cached faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-1f9f8c3f-cafb-4adf-b977-3cd5e962e34f/lib/python3.12/site-packages (from faiss-cpu) (2.2.6)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.12/site-packages (from faiss-cpu) (24.1)\nUsing cached faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.7 MB)\nInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.13.1\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#%pip install megadetector\n",
    "#%pip install dbutils\n",
    "#%pip install yolov5\n",
    "#%pip install torch \n",
    "#%pip install torchvision\n",
    "# %pip install numpy==1.26.4\n",
    "# %pip install supervision\n",
    "# %pip install lightning\n",
    "# %pip install omegaconf\n",
    "#%pip install ultralytics\n",
    "%pip install torch\n",
    "%pip install ultralytics\n",
    "%pip install pytesseract\n",
    "%pip install config\n",
    "%pip install yolov5\n",
    "%pip install faiss-cpu\n",
    "#%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1676f026-163d-479b-afd9-7ae815689735",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#always needed\n",
    "import config\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch #GPU version\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "#data preprocessing librariesa\n",
    "import cv2,pytesseract\n",
    "from PIL import Image,ImageStat\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import functions as when\n",
    "from pyspark.sql import Row\n",
    "\n",
    "from pyspark.sql.functions import col, input_file_name, lit, current_timestamp, split, element_at, regexp_extract\n",
    "from pyspark.sql.functions import col, substring, length\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType,BooleanType, FloatType, StringType,BinaryType,LongType, TimestampType\n",
    "from pyspark.sql.functions import sha2, expr\n",
    "from pyspark.sql.functions import hash as spark_hash, pmod\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.functions import udf\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "#model related libraries\n",
    "from ultralytics import YOLO #for YOLOv9\n",
    "from pathlib import Path\n",
    "\n",
    "#others\n",
    "import requests # Define the URL and the local file path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aefefe5-c788-464d-92f9-5e2125b0e35f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# define the year of photoes for table names\n",
    "photo_year=\"2024\"\n",
    "\n",
    "# schema of the output\n",
    "schema= \"meadowbank_prod\"\n",
    "\n",
    "# define output of this model's name and location, ex. md24v6 then final table will be \n",
    "process_name=\"md24_tws\"\n",
    "\n",
    "# Volume root path\n",
    "volume_root = \"/Volumes/meadowbank_prod/remote_cameras/mbk_remote_cameras_blob/2024/\"\n",
    "\n",
    "# designated folder for animal output images\n",
    "output_uc_folder=\"/Volumes/meadowbank_prod/remote_cameras/mbk_remote_cameras_blob/results/2024_TWS/wildlife_test/\"\n",
    "\n",
    "# generate the Volume table in catalog with 2.5 million images including final model output\n",
    "manifest_table=f\"{schema}.remote_cameras.{process_name}_manifest_{photo_year}\"\n",
    "\n",
    "manifest_timestamp_table=f\"{schema}.remote_cameras.{process_name}_manifest_timestamp_{photo_year}\"\n",
    "\n",
    "manifest_prefiltered_table = f\"{schema}.remote_cameras.{process_name}_manifest_prefiltered_{photo_year}\"\n",
    "\n",
    "model_table=f\"{schema}.remote_cameras.{process_name}_megadetector_model_{photo_year}\"\n",
    "\n",
    "model_output_table=f\"{schema}.remote_cameras.{process_name}_megadetector_v5a_v6byolo9c_results_{photo_year}\"\n",
    "\n",
    "manifest_table_final=f\"{schema}.remote_cameras.{process_name}_manifest_{photo_year}_final\"\n",
    "\n",
    "# manifest final output table for final_category to classify images\n",
    "animal_confidence_threshold=0.5\n",
    "vehicle_confidence_threshold=0.3\n",
    "human_confidence_threshold=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5c606d1-5a57-41f0-87f4-0686851fab43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#load the manifest table meadowbank_prod.remote_cameras.md24_tws_manifest\n",
    "df = spark.sql(f\"select * from {manifest_table}\")\n",
    "\n",
    "#load the manifest table with timestamp meadowbank_prod.remote_cameras.md24_tws_manifest_timestamp \n",
    "df_ts = spark.sql(f\"select * from {manifest_timestamp_table}\")\n",
    "\n",
    "#load the manifest table\n",
    "# df = spark.sql(f\"select * from meadowbank_prod.remote_cameras.md24_tws_manifest\")\n",
    "\n",
    "#load the manifest table with timestamp\n",
    "# df_ts = spark.sql(f\"select * from meadowbank_prod.remote_cameras.md24_tws_manifest_timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "758e5e9b-f1b2-4b73-9a78-f360032a4a5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create tm_indicator\n",
    "df_ts = df_ts.withColumn(\n",
    "    \"TM_flag\",\n",
    "    F.when(F.col(\"timestamp\").endswith(\"0:00\"), \"T\").otherwise(\"M\")\n",
    ")\n",
    "\n",
    "df_ts = df_ts.withColumnRenamed(\"path\", \"image_path\")\n",
    "\n",
    "df_join=df.join(df_ts, on='image_path')\n",
    "\n",
    "# add a column 'pre-filtered' with logic saying if file_size<105 or tm_indicator=='T' then 'True' else 'False'\n",
    "df_pre_filtered = df_join.withColumn(\n",
    "    \"pre_filtered\",\n",
    "    F.when(\n",
    "        (col(\"file_size_kb\") < 105) | (col(\"TM_flag\") == \"T\"),\n",
    "        True\n",
    "    ).otherwise(False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ff4899c-8589-48cd-ad92-56a5cc494f78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write to Catalog Volum, if already did, no need to redo again\n",
    "# df_pre_filtered.write.format(\"delta\") \\\n",
    "#     .mode(\"overwrite\") \\\n",
    "#     .option(\"overwriteSchema\", \"true\") \\\n",
    "#     .saveAsTable(manifest_prefiltered_table)\n",
    "\n",
    "# print(\"✅ joined_df with pre_filtered column successfully written to {manifest_prefiltered_table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76f6fe1c-f0e6-48cb-8479-a5d94e3c32bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n|pre_filtered|  count|\n+------------+-------+\n|       false|2173531|\n|        true| 326800|\n+------------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "df_pre_filtered.groupBy(\"pre_filtered\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eff6faa4-04e7-4a35-8831-061c432e7276",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2173531"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for watermark analyses -> B10\n",
    "# identify images will be excluded by the filter\n",
    "a = df_pre_filtered.filter(col(\"pre_filtered\") == True)\n",
    "a.count() \n",
    "\n",
    "# identify images will NOT be excluded by the filter\n",
    "filtered_df = df_pre_filtered.filter(col(\"pre_filtered\") == False)\n",
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89a67d85-b655-4291-be86-cacad49dcba9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1279887"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the table will run through the models\n",
    "df_model = spark.sql(f\"select * from {model_table}\")\n",
    "df_model.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5388cbb8-fbf3-4db8-87c3-b9fa604a257c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#get all the model image path\n",
    "model_paths = df_model.select(\"image_path\").distinct()\n",
    "\n",
    "#create a new column mg5a_binary to df_pre_filtered table\n",
    "df_pre_filtered_flagged = (\n",
    "    df_pre_filtered\n",
    "        .join(model_paths.withColumn(\"in_model\", F.lit(True)),\n",
    "              on=\"image_path\",\n",
    "              how=\"left\")\n",
    "        .withColumn(\n",
    "            \"mg5a_binary\",\n",
    "            F.when(\n",
    "                (F.col(\"pre_filtered\") == True) & (F.col(\"in_model\") == True),\n",
    "                True\n",
    "            )\n",
    "            .otherwise(False)\n",
    "        )\n",
    "        .drop(\"in_model\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b0ae985-076b-4309-af02-d347d5e5fda2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n|mg5a_binary|  count|\n+-----------+-------+\n|      false|2409233|\n|       true|  91098|\n+-----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# for waterfall analyses true count -> B13\n",
    "df_pre_filtered_flagged.groupBy(\"mg5a_binary\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec0b472f-aa93-4162-b269-3c02a7b356d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df_pre_filtered_flagged.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4058ce0-dfe8-4ac2-abce-d7ed7e8d8549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "956874"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model_output=spark.sql(f\"select * from {model_output_table}\")\n",
    "df_model_output.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbe5c1f2-5e63-4c30-a832-b38cb24b43e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df_model_output.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73ebcea6-f7f7-4cb5-bc8e-29f7537ea975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Remove \"dbfs:\" from image_path\n",
    "df_pre_clean = df_pre_filtered_flagged.withColumn(\n",
    "    \"image_path\",\n",
    "    F.regexp_replace(\"image_path\", \"^dbfs:\", \"\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2da312ea-03af-46e5-9ab0-4b0bda03ae85",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#df_model_output.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e04adaf8-884c-41a1-98a0-2a4fe0a9ae49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# exclude all tagged images from camera 4\n",
    "df_model_output_no_camera4 = df_model_output.filter(~F.col(\"image_path\").contains(\"Camera 4\"))\n",
    "\n",
    "#apply threshold to individual images\n",
    "#For vehicles (category 3) → conf_md5a ≥ vehicle_threshold AND conf_md9c ≥ vehicle_threshold\n",
    "#For animals (category 1) → conf_md5a ≥ animal_threshold AND conf_md9c ≥ animal_threshold\n",
    "#For humans (category 2) → conf_md5a ≥ human_threshold AND conf_md9c ≥ human_threshold\n",
    "\n",
    "df_results = (\n",
    "    df_model_output_no_camera4\n",
    "    .filter(\n",
    "        (\n",
    "            (F.col(\"category\") == \"3\") &\n",
    "            (F.col(\"conf_md5a\") >= vehicle_confidence_threshold) &\n",
    "            (F.col(\"conf_md9c\") >= vehicle_confidence_threshold)\n",
    "        ) |\n",
    "        (\n",
    "            (F.col(\"category\") == \"1\") &\n",
    "            (F.col(\"conf_md5a\") >= animal_confidence_threshold) &\n",
    "            (F.col(\"conf_md9c\") >= animal_confidence_threshold)\n",
    "        ) |\n",
    "        (\n",
    "            (F.col(\"category\") == \"2\") &\n",
    "            (F.col(\"conf_md5a\") >= human_confidence_threshold) &\n",
    "            (F.col(\"conf_md9c\") >= human_confidence_threshold)\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4590efb9-4533-438d-bd54-92ffaf16709e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n|category|distinct_image_count|\n+--------+--------------------+\n|       1|                5458|\n|       2|                1368|\n|       3|              334250|\n+--------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "#the numbers of distinct images for each category, used for output workflow\n",
    "df_results.groupBy(\"category\") \\\n",
    "    .agg(F.countDistinct(\"image_path\").alias(\"distinct_image_count\")) \\\n",
    "    .orderBy(\"category\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2aa084c-d48c-48e4-bfe4-989ad98a08ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "#create mapping from code into category words\n",
    "category_map = {\n",
    "    \"1\": \"animals\",\n",
    "    \"2\": \"humans\",\n",
    "    \"3\": \"vehicles\"\n",
    "}\n",
    "\n",
    "# Convert category into its name\n",
    "df_named = df_results.withColumn(\n",
    "    \"category_name\",\n",
    "    F.when(F.col(\"category\") == \"1\", \"Animals\")\n",
    "     .when(F.col(\"category\") == \"2\", \"Humans\")\n",
    "     .when(F.col(\"category\") == \"3\", \"Vehicles\")\n",
    ")\n",
    "\n",
    "df_grouped = (\n",
    "    df_named\n",
    "        .groupBy(\"image_path\")\n",
    "        .agg(\n",
    "            F.concat_ws(\", \", F.array_distinct(F.collect_list(\"category_name\")))\n",
    "             .alias(\"final_category\")\n",
    "        )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9ff2d04-54cc-4fdf-a10c-bd43aa1c665b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# df_grouped.show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1d1d1e2-19d2-4bd8-862e-cd816d0414de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----------+\n|final_category           |image_count|\n+-------------------------+-----------+\n|Vehicles                 |331929     |\n|Animals                  |3516       |\n|Animals, Vehicles        |1939       |\n|Humans                   |985        |\n|Humans, Vehicles         |380        |\n|Animals, Humans, Vehicles|2          |\n|Animals, Humans          |1          |\n+-------------------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df_final_counts = (\n",
    "    df_grouped\n",
    "        .groupBy(\"final_category\")\n",
    "        .agg(F.count(\"*\").alias(\"image_count\"))\n",
    "        .orderBy(\"image_count\", ascending=False)\n",
    ")\n",
    "\n",
    "df_final_counts.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8fc3c73-8062-466a-94b6-b1034aa33c45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct image_path: 338752\n"
     ]
    }
   ],
   "source": [
    "#check no duplicates for image_path\n",
    "distinct_count = df_grouped.select(F.countDistinct(\"image_path\")).first()[0]\n",
    "print(\"Distinct image_path:\", distinct_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26cd5cb1-7751-49b2-b82e-eeb7724eb9e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Map categories to readable names\n",
    "df_named = df_model_output.withColumn(\n",
    "    \"category_name\",\n",
    "    F.when(F.col(\"category\") == \"1\", \"animals\")\n",
    "     .when(F.col(\"category\") == \"2\", \"humans\")\n",
    "     .when(F.col(\"category\") == \"3\", \"vehicles\")\n",
    ")\n",
    "\n",
    "# 2. Create one detection JSON per row \n",
    "df_struct = df_named.withColumn(\n",
    "    \"detection_json\",\n",
    "    F.to_json(\n",
    "        F.struct(\n",
    "            F.col(\"category_name\").alias(\"category\"),\n",
    "            F.col(\"conf_md5a\"),\n",
    "            F.col(\"bbox_md5a\"),\n",
    "            F.col(\"conf_md9c\"),\n",
    "            F.col(\"bbox_md9c\")\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Group by image_path → collect ALL detections for that image\n",
    "df_grouped_per_image = (\n",
    "    df_struct\n",
    "        .groupBy(\"image_path\")\n",
    "        .agg(\n",
    "            F.collect_list(\"detection_json\").alias(\"json_output\")\n",
    "        )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aff195d-59a3-48ab-a26b-39a4ceedb775",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#show the images that belongs to more than one cateogries\n",
    "# df_grouped.filter(\n",
    "#     F.size(F.split(F.col(\"final_category\"), \",\\\\s*\")) > 1\n",
    "# ).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50492af1-dfb7-4bf8-b900-6865d275fa36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|image_path                                                                                                              |json_output                                                                                                                                                                                                                                                                  |\n+------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|/Volumes/meadowbank_prod/remote_cameras/mbk_remote_cameras_blob/2024/FirstPart/Camera 1/2024-05-29/100RECNX/RCNX8065.JPG|[{\"category\":\"animals\",\"conf_md5a\":0.561,\"bbox_md5a\":[0.66,0.661,0.018,0.057],\"conf_md9c\":0.593,\"bbox_md9c\":[0.66,0.66,0.019,0.057]}, {\"category\":\"vehicles\",\"conf_md5a\":0.776,\"bbox_md5a\":[0.917,0.59,0.167,0.316],\"conf_md9c\":0.607,\"bbox_md9c\":[0.917,0.597,0.167,0.299]}]|\n+------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "#take one of the image_path from output above, QA on output\n",
    "#for example this file path below has both animals and vehicles, then json_output will show: [{\"category\":\"animals\",\"conf_md5a\":0.561,\"bbox_md5a\":[0.66,0.661,0.018,0.057],\"conf_md9c\":0.593,\"bbox_md9c\":[0.66,0.66,0.019,0.057]}, {\"category\":\"vehicles\",\"conf_md5a\":0.776,\"bbox_md5a\":[0.917,0.59,0.167,0.316],\"conf_md9c\":0.607,\"bbox_md9c\":[0.917,0.597,0.167,0.299]}]\n",
    "\n",
    "df_grouped_per_image.filter(\n",
    "    F.col(\"image_path\") == \"/Volumes/meadowbank_prod/remote_cameras/mbk_remote_cameras_blob/2024/FirstPart/Camera 1/2024-05-29/100RECNX/RCNX8065.JPG\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9757d6b-aca5-488b-bc67-7bcd37761c59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Perform the join with df_model_output\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Step 1 — select only needed columns from df_grouped\n",
    "df_final_cat = df_grouped.select(\"image_path\", \"final_category\")\n",
    "\n",
    "# Step 2 — join df_pre_clean with df_grouped on image_path\n",
    "df_join1 = (\n",
    "    df_pre_clean.alias(\"a\")\n",
    "        .join(df_final_cat.alias(\"b\"), on=\"image_path\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Step 3 — select only needed columns from df_grouped_per_image\n",
    "df_json = df_grouped_per_image.select(\"image_path\", \"json_output\")\n",
    "\n",
    "# Step 4 — join the result with df_grouped_per_image\n",
    "df_manifest_final = (\n",
    "    df_join1.alias(\"c\")\n",
    "        .join(df_json.alias(\"d\"), on=\"image_path\", how=\"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "077148b3-2077-45cd-a307-1b44776efbf2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#QA check, should be the same count to indicate the final_manifest table has all the images populated\n",
    "df_ts.count()==df_manifest_final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48e11350-317a-4b69-9a09-a7415b01beb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Write to Catalog Volum, if already did, no need to redo again\n",
    "\n",
    "df_manifest_final.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(manifest_table_final)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Output 1. Generate Final Manifest Table",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}